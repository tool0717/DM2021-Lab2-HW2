{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp = []\n",
    "f = open('./tweets_DM.txt',\"r\")\n",
    "for line in f.readlines():\n",
    "    temp.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(temp)):\n",
    "    st = temp[i].index(\"tweet_id\")\n",
    "    l = len(\"tweet_id\")\n",
    "    temp[i] = temp[i].replace(temp[i][:st-1], \"\").replace('\"tweet_id\": ','')\n",
    "    \n",
    "    st = temp[i].index('}}, \"_crawldate\"')\n",
    "    l = len(', \"_crawldate\"')\n",
    "    temp[i] = temp[i].replace(temp[i][st:], \"\").replace('\"text\": ','')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv('data_identification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label.rename(columns = {\"tweet_id\":\"id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "count = 0\n",
    "for i in temp:\n",
    "    count += 1\n",
    "    if count%10000==0:\n",
    "        print(count)\n",
    "    d = i.split('\", \"')\n",
    "    d[0] = d[0].replace('\"','')\n",
    "    d[1] = d[1].replace('\"','')\n",
    "    data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(data, columns = ['id','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \\add me on #Snapchat\\ must be ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha \\ud83d\\ude02\\ud83d\\...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\\Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "0        0x376b20  People who post \\add me on #Snapchat\\ must be ...   \n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2        0x28b412  Confident of your obedience, I write to you, k...   \n",
       "3        0x1cd5b0  Now ISSA is stalking Tasha \\ud83d\\ude02\\ud83d\\...   \n",
       "4        0x2de201  \\Trust is not the same as faith. A friend is s...   \n",
       "...           ...                                                ...   \n",
       "1867530  0x316b80  When you buy the last 2 tickets remaining for ...   \n",
       "1867531  0x29d0cb  I swear all this hard work gone pay off one da...   \n",
       "1867532  0x2a6a4f  @Parcel2Go no card left when I wasn't in so I ...   \n",
       "1867533  0x24faed  Ah, corporate life, where you can date <LH> us...   \n",
       "1867534  0x34be8c             Blessed to be living #Sundayvibes <LH>   \n",
       "\n",
       "        identification  \n",
       "0                train  \n",
       "1                train  \n",
       "2                 test  \n",
       "3                train  \n",
       "4                 test  \n",
       "...                ...  \n",
       "1867530           test  \n",
       "1867531           test  \n",
       "1867532           test  \n",
       "1867533          train  \n",
       "1867534          train  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_temp.merge(df_label,how = \"outer\", on = 'id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(df.identification)\n",
    "df_train = groups.get_group('train')\n",
    "df_test = groups.get_group('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>identification</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \\add me on #Snapchat\\ must be ...</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>train</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha \\ud83d\\ude02\\ud83d\\...</td>\n",
       "      <td>train</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455558</th>\n",
       "      <td>0x321566</td>\n",
       "      <td>I'm SO HAPPY!!! #NoWonder the name of this sho...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455559</th>\n",
       "      <td>0x38959e</td>\n",
       "      <td>In every circumtance I'd like to be thankful t...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455560</th>\n",
       "      <td>0x2cbca6</td>\n",
       "      <td>there's currently two girls walking around the...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455561</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455562</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "      <td>train</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                               text  \\\n",
       "0        0x376b20  People who post \\add me on #Snapchat\\ must be ...   \n",
       "1        0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n",
       "2        0x1cd5b0  Now ISSA is stalking Tasha \\ud83d\\ude02\\ud83d\\...   \n",
       "3        0x1d755c  @RISKshow @TheKevinAllison Thx for the BEST TI...   \n",
       "4        0x2c91a8       Still waiting on those supplies Liscus. <LH>   \n",
       "...           ...                                                ...   \n",
       "1455558  0x321566  I'm SO HAPPY!!! #NoWonder the name of this sho...   \n",
       "1455559  0x38959e  In every circumtance I'd like to be thankful t...   \n",
       "1455560  0x2cbca6  there's currently two girls walking around the...   \n",
       "1455561  0x24faed  Ah, corporate life, where you can date <LH> us...   \n",
       "1455562  0x34be8c             Blessed to be living #Sundayvibes <LH>   \n",
       "\n",
       "        identification       emotion  \n",
       "0                train  anticipation  \n",
       "1                train       sadness  \n",
       "2                train          fear  \n",
       "3                train           joy  \n",
       "4                train  anticipation  \n",
       "...                ...           ...  \n",
       "1455558          train           joy  \n",
       "1455559          train           joy  \n",
       "1455560          train           joy  \n",
       "1455561          train           joy  \n",
       "1455562          train           joy  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_emotion = pd.read_csv('emotion.csv')\n",
    "df_train_emotion = df_train_emotion.rename(columns = {'tweet_id':'id'})\n",
    "df_train = df_train.merge(df_train_emotion, how = \"outer\", on = \"id\")\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             516017\n",
       "anticipation    248935\n",
       "trust           205478\n",
       "sadness         193437\n",
       "disgust         139101\n",
       "fear             63999\n",
       "surprise         48729\n",
       "anger            39867\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.text = df_train.text.str.replace('<LH>', '')\n",
    "df.text = df.text.str.replace('@','').str.replace('#','')\n",
    "# for i in df_train.text[1000:2000]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    input_txt = re.sub(pattern, '', input_txt)\n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-522a4214cec8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['tidy'] = ''\n",
      "C:\\Users\\Lee\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "df_train['tidy'] = ''\n",
    "df_train.tidy = df_train.text.apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
    "df_test['tidy'] = ''\n",
    "df_test.tidy = df_test.text.apply(lambda x: re.sub(\"@[\\w]*\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "def get_tokenize():\n",
    "    return nltk.RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer(max_features = 1000000, stop_words = {'english'}, tokenizer = get_tokenize(),\n",
    "                             strip_accents='unicode', ngram_range = (1,2)) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BOW_features = tfidf_vect.fit_transform(df_train.text)\n",
    "test_BOW_features = tfidf_vect.fit_transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BOW_features = tfidf_vect.transform(df_train.text)\n",
    "test_BOW_features = tfidf_vect.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '00',\n",
       " '000',\n",
       " '000000',\n",
       " '00000000001',\n",
       " '000000009',\n",
       " '000001',\n",
       " '000004',\n",
       " '00001',\n",
       " '00002',\n",
       " '0001',\n",
       " '0003',\n",
       " '0006',\n",
       " '00072240',\n",
       " '0007foz',\n",
       " '00085',\n",
       " '00088395',\n",
       " '00089',\n",
       " '000997480',\n",
       " '000cr',\n",
       " '000destiny',\n",
       " '000ff',\n",
       " '000ft',\n",
       " '000k',\n",
       " '000m',\n",
       " '000s',\n",
       " '000th',\n",
       " '000x',\n",
       " '001',\n",
       " '00100110111001010',\n",
       " '0011',\n",
       " '00148',\n",
       " '00176016',\n",
       " '001s',\n",
       " '002',\n",
       " '0020',\n",
       " '002s',\n",
       " '003',\n",
       " '004',\n",
       " '00412',\n",
       " '0045',\n",
       " '00533321btc',\n",
       " '007',\n",
       " '0071639',\n",
       " '007asylum',\n",
       " '007gal',\n",
       " '007ofnj',\n",
       " '008',\n",
       " '0081',\n",
       " '00a',\n",
       " '00am',\n",
       " '00ftme',\n",
       " '00h',\n",
       " '00hitsdiidii',\n",
       " '00htina',\n",
       " '00p',\n",
       " '00pm',\n",
       " '00pmest',\n",
       " '00s',\n",
       " '01',\n",
       " '010',\n",
       " '010101010101',\n",
       " '0102',\n",
       " '0103',\n",
       " '0105hrs',\n",
       " '011',\n",
       " '0111hrs',\n",
       " '0112747786',\n",
       " '011365',\n",
       " '0120',\n",
       " '01203',\n",
       " '0122',\n",
       " '01243',\n",
       " '013',\n",
       " '01353',\n",
       " '014',\n",
       " '0151',\n",
       " '01516529157',\n",
       " '016',\n",
       " '0161',\n",
       " '01618145889',\n",
       " '01625',\n",
       " '01702334649',\n",
       " '0172pop',\n",
       " '0182827328292',\n",
       " '01829',\n",
       " '01892',\n",
       " '019',\n",
       " '01903522966',\n",
       " '01912501901',\n",
       " '01914214848',\n",
       " '0192',\n",
       " '01952',\n",
       " '01am',\n",
       " '01fa',\n",
       " '01irish',\n",
       " '01pm',\n",
       " '01starblazer',\n",
       " '01that',\n",
       " '01x13',\n",
       " '02',\n",
       " '020',\n",
       " '0202',\n",
       " '0203',\n",
       " '020416',\n",
       " '0208',\n",
       " '02085100755',\n",
       " '021',\n",
       " '02136',\n",
       " '0218',\n",
       " '022',\n",
       " '0220',\n",
       " '023',\n",
       " '0246',\n",
       " '02732',\n",
       " '029',\n",
       " '02am',\n",
       " '02apollomanc',\n",
       " '02pm',\n",
       " '03',\n",
       " '030',\n",
       " '0300',\n",
       " '03007064072',\n",
       " '031',\n",
       " '03103586565',\n",
       " '0321jail',\n",
       " '0330',\n",
       " '0344',\n",
       " '0345',\n",
       " '0350',\n",
       " '0358',\n",
       " '035th',\n",
       " '038',\n",
       " '03am',\n",
       " '03greedo',\n",
       " '03h00',\n",
       " '04',\n",
       " '0400',\n",
       " '0400am',\n",
       " '04011',\n",
       " '0412afrxn',\n",
       " '0416',\n",
       " '0418gm',\n",
       " '0420',\n",
       " '042gossip',\n",
       " '044',\n",
       " '045',\n",
       " '0458791556',\n",
       " '0472451341',\n",
       " '048',\n",
       " '049777',\n",
       " '04am',\n",
       " '04mb',\n",
       " '05',\n",
       " '0500',\n",
       " '052',\n",
       " '0524',\n",
       " '0530',\n",
       " '054',\n",
       " '055',\n",
       " '0580',\n",
       " '05am',\n",
       " '05jkelly',\n",
       " '05p',\n",
       " '05pm',\n",
       " '06',\n",
       " '060',\n",
       " '06010',\n",
       " '061',\n",
       " '0611',\n",
       " '062',\n",
       " '0630',\n",
       " '0638',\n",
       " '0640hrs',\n",
       " '0645',\n",
       " '066',\n",
       " '06800',\n",
       " '06am',\n",
       " '06pm',\n",
       " '07',\n",
       " '070',\n",
       " '0700',\n",
       " '0701',\n",
       " '0703',\n",
       " '0705',\n",
       " '0710',\n",
       " '071010',\n",
       " '0718',\n",
       " '0719218677',\n",
       " '072517',\n",
       " '0725ferry',\n",
       " '0729',\n",
       " '0755',\n",
       " '0759',\n",
       " '076',\n",
       " '07855',\n",
       " '07973',\n",
       " '07984609542',\n",
       " '07cbxxj17xgdhnltwh44ml',\n",
       " '07mins',\n",
       " '07musty',\n",
       " '07p',\n",
       " '07pm',\n",
       " '07reddevilz',\n",
       " '08',\n",
       " '0800',\n",
       " '0800phantom',\n",
       " '0808',\n",
       " '08094710310',\n",
       " '0811',\n",
       " '0815',\n",
       " '0818',\n",
       " '082',\n",
       " '0821',\n",
       " '08245',\n",
       " '0830',\n",
       " '0835',\n",
       " '085',\n",
       " '0860100762',\n",
       " '0899',\n",
       " '08a',\n",
       " '08am',\n",
       " '08jayhawk',\n",
       " '08jcrossan',\n",
       " '08km',\n",
       " '08m',\n",
       " '08mb',\n",
       " '08p',\n",
       " '08pm',\n",
       " '09',\n",
       " '0900',\n",
       " '091',\n",
       " '091217',\n",
       " '0917',\n",
       " '0922865222',\n",
       " '093',\n",
       " '0930',\n",
       " '0945',\n",
       " '0955',\n",
       " '0956',\n",
       " '096',\n",
       " '097',\n",
       " '09am',\n",
       " '09emmar',\n",
       " '09latoyamason',\n",
       " '09mb',\n",
       " '09pm',\n",
       " '09sarahiespino',\n",
       " '09sharkboy',\n",
       " '09stash',\n",
       " '0abdullah4',\n",
       " '0apes0',\n",
       " '0asls',\n",
       " '0bb',\n",
       " '0d',\n",
       " '0data',\n",
       " '0ddj0b',\n",
       " '0di',\n",
       " '0ffice0ffrg',\n",
       " '0follower',\n",
       " '0h',\n",
       " '0hour1',\n",
       " '0l',\n",
       " '0maia0',\n",
       " '0mg',\n",
       " '0mins',\n",
       " '0mysky',\n",
       " '0n',\n",
       " '0nce',\n",
       " '0ne2w0',\n",
       " '0nepr0udm0mmy',\n",
       " '0nn',\n",
       " '0o',\n",
       " '0ppl',\n",
       " '0r',\n",
       " '0r65',\n",
       " '0roaringtiger0',\n",
       " '0s',\n",
       " '0skig',\n",
       " '0tds',\n",
       " '0tralala',\n",
       " '0txt',\n",
       " '0ty',\n",
       " '0utrageous',\n",
       " '0ver',\n",
       " '0vernment',\n",
       " '0w3n',\n",
       " '0wn',\n",
       " '0x00000204',\n",
       " '0x04b47db41381f6ef9f7aae43d2d32bc27f86469f',\n",
       " '0x2c64be1e612dc8c35f0431e105c462d1a4762e1032f377addd5c0fa112595874',\n",
       " '0xa5fd0114e64e44da777530a54b394b859b045ca9',\n",
       " '0xdbe',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100000',\n",
       " '10000000',\n",
       " '100000000',\n",
       " '10000000000',\n",
       " '10000000000000x',\n",
       " '1000000x',\n",
       " '100000897122255',\n",
       " '100000dollarchallenge',\n",
       " '100000rs',\n",
       " '100000x',\n",
       " '10000hrs',\n",
       " '10000km',\n",
       " '10000reasons',\n",
       " '10000x',\n",
       " '1000blackgirlbooks',\n",
       " '1000cal',\n",
       " '1000cores',\n",
       " '1000degreepizza',\n",
       " '1000degrees',\n",
       " '1000gifts',\n",
       " '1000legger',\n",
       " '1000m',\n",
       " '1000mg',\n",
       " '1000mph',\n",
       " '1000s',\n",
       " '1000steps',\n",
       " '1000subs',\n",
       " '1000th',\n",
       " '1000waystodie',\n",
       " '1000x',\n",
       " '1000xs',\n",
       " '1000yrd',\n",
       " '1001',\n",
       " '1003thebear',\n",
       " '1004',\n",
       " '1008',\n",
       " '1009km',\n",
       " '100aed',\n",
       " '100awesomeness',\n",
       " '100b',\n",
       " '100babychallenge',\n",
       " '100billionx',\n",
       " '100bn',\n",
       " '100br',\n",
       " '100cc',\n",
       " '100ct',\n",
       " '100days',\n",
       " '100daysofcode',\n",
       " '100deg',\n",
       " '100fifty',\n",
       " '100fold',\n",
       " '100g',\n",
       " '100goals',\n",
       " '100grand',\n",
       " '100gs',\n",
       " '100happydays',\n",
       " '100hrs',\n",
       " '100huntley',\n",
       " '100hype',\n",
       " '100ideas',\n",
       " '100inc',\n",
       " '100k',\n",
       " '100kb',\n",
       " '100kg',\n",
       " '100km',\n",
       " '100kph',\n",
       " '100ks',\n",
       " '100lb',\n",
       " '100lbacolliweed',\n",
       " '100letters',\n",
       " '100likes',\n",
       " '100m',\n",
       " '100mb',\n",
       " '100mbeliebers',\n",
       " '100mbps',\n",
       " '100mfinal',\n",
       " '100mg',\n",
       " '100mh',\n",
       " '100mil',\n",
       " '100million',\n",
       " '100millionbeliebers',\n",
       " '100more',\n",
       " '100mph',\n",
       " '100ms',\n",
       " '100of100',\n",
       " '100pages',\n",
       " '100passchendaele',\n",
       " '100percent',\n",
       " '100percentguess',\n",
       " '100percentpurelove',\n",
       " '100percfedup',\n",
       " '100points',\n",
       " '100rats',\n",
       " '100s',\n",
       " '100startup',\n",
       " '100stumping',\n",
       " '100subs',\n",
       " '100th',\n",
       " '100times',\n",
       " '100x',\n",
       " '100xp',\n",
       " '100yards',\n",
       " '100yds',\n",
       " '100yearquote',\n",
       " '100years',\n",
       " '100yearswar',\n",
       " '100yrs',\n",
       " '101',\n",
       " '1010',\n",
       " '10100',\n",
       " '101010101010',\n",
       " '1010traffic',\n",
       " '1010xl',\n",
       " '1011',\n",
       " '101110101',\n",
       " '10112',\n",
       " '101178',\n",
       " '1011wjrr',\n",
       " '1012',\n",
       " '1012000',\n",
       " '1013',\n",
       " '10137649220',\n",
       " '1013kdwb',\n",
       " '1014',\n",
       " '1015',\n",
       " '1016',\n",
       " '101a',\n",
       " '101dayschangeyourlifetoday',\n",
       " '101family',\n",
       " '101k',\n",
       " '101powerthoughts',\n",
       " '101wkqx',\n",
       " '101wkqxlolla',\n",
       " '102',\n",
       " '1020',\n",
       " '10208strong',\n",
       " '10210',\n",
       " '102257628',\n",
       " '1022wesayido',\n",
       " '102321429',\n",
       " '1023nowradio',\n",
       " '1024',\n",
       " '1025',\n",
       " '1025thebone',\n",
       " '1025thegame',\n",
       " '1027',\n",
       " '10270strong',\n",
       " '1027dabomb',\n",
       " '1027kiisfm',\n",
       " '1027kj103',\n",
       " '1029tak',\n",
       " '1029thebuzz',\n",
       " '102f',\n",
       " '103',\n",
       " '1030',\n",
       " '10300',\n",
       " '1030isnotlunchtime',\n",
       " '1030pm',\n",
       " '1031wogb',\n",
       " '103295',\n",
       " '1033theedge',\n",
       " '1035',\n",
       " '1035kissfm',\n",
       " '1035klite',\n",
       " '1035thefox',\n",
       " '103623',\n",
       " '10362strong',\n",
       " '1038764747',\n",
       " '1038863278',\n",
       " '103fm',\n",
       " '103k',\n",
       " '103rd',\n",
       " '104',\n",
       " '1040',\n",
       " '1043freshradio',\n",
       " '1043now',\n",
       " '1043thefan',\n",
       " '1045',\n",
       " '1045chumfm',\n",
       " '1045hrs',\n",
       " '1045theteam',\n",
       " '1045thezone',\n",
       " '1047heartfm',\n",
       " '1049swag',\n",
       " '104ctk111017',\n",
       " '104k',\n",
       " '105',\n",
       " '1050',\n",
       " '1052',\n",
       " '1053ss',\n",
       " '1054120783',\n",
       " '1055theroar',\n",
       " '1057fmthefan',\n",
       " '1057thefan',\n",
       " '105e',\n",
       " '105percent',\n",
       " '105uckfieldfm',\n",
       " '106',\n",
       " '1060',\n",
       " '10606',\n",
       " '1061chez',\n",
       " '106288157484',\n",
       " '1065fm',\n",
       " '1065wyrk',\n",
       " '1067litefm',\n",
       " '1067thefan',\n",
       " '1067wtlc',\n",
       " '106s',\n",
       " '107',\n",
       " '1070',\n",
       " '1070thefan',\n",
       " '1075theriver',\n",
       " '1076',\n",
       " '10762933',\n",
       " '1079thebear',\n",
       " '107cm',\n",
       " '107th',\n",
       " '108',\n",
       " '1080',\n",
       " '1080p',\n",
       " '1088',\n",
       " '1089',\n",
       " '108malasoflove',\n",
       " '108mins',\n",
       " '109',\n",
       " '1090',\n",
       " '1090t',\n",
       " '1096',\n",
       " '1098',\n",
       " '10a',\n",
       " '10am',\n",
       " '10amedt',\n",
       " '10amet',\n",
       " '10ast',\n",
       " '10aud',\n",
       " '10b',\n",
       " '10becks10',\n",
       " '10c',\n",
       " '10canbananamilk',\n",
       " '10coleman',\n",
       " '10commandments',\n",
       " '10commandsofgod',\n",
       " '10cr',\n",
       " '10dayengagements',\n",
       " '10days',\n",
       " '10daysofcod',\n",
       " '10daystogo',\n",
       " '10dec',\n",
       " '10dundaseast',\n",
       " '10e',\n",
       " '10ft',\n",
       " '10fwy',\n",
       " '10g',\n",
       " '10gb',\n",
       " '10gm',\n",
       " '10gours',\n",
       " '10hour',\n",
       " '10hourday',\n",
       " '10hoursofsleep',\n",
       " '10hr',\n",
       " '10hrs',\n",
       " '10in',\n",
       " '10inarow',\n",
       " '10ish',\n",
       " '10jaffa',\n",
       " '10jaisy10',\n",
       " '10jayy',\n",
       " '10jp',\n",
       " '10jul',\n",
       " '10k',\n",
       " '10kers',\n",
       " '10kg',\n",
       " '10kgs',\n",
       " '10kleaders2020',\n",
       " '10km',\n",
       " '10ks',\n",
       " '10l',\n",
       " '10lacs',\n",
       " '10lb',\n",
       " '10lbs',\n",
       " '10m',\n",
       " '10mb',\n",
       " '10mbps',\n",
       " '10men',\n",
       " '10mil',\n",
       " '10million',\n",
       " '10min',\n",
       " '10mindq',\n",
       " '10mins',\n",
       " '10mns',\n",
       " '10mo',\n",
       " '10month',\n",
       " '10months',\n",
       " '10monthsinflorida',\n",
       " '10monthsold',\n",
       " '10more',\n",
       " '10newswtsp',\n",
       " '10niv',\n",
       " '10o',\n",
       " '10oct',\n",
       " '10p',\n",
       " '10pm',\n",
       " '10pmwnadiamirza',\n",
       " '10points',\n",
       " '10pr4',\n",
       " '10psharp',\n",
       " '10pts',\n",
       " '10quidshoes',\n",
       " '10ronaldinho',\n",
       " '10rule',\n",
       " '10s',\n",
       " '10sac1975',\n",
       " '10sec',\n",
       " '10seconds',\n",
       " '10secs',\n",
       " '10th',\n",
       " '10thavenuetea',\n",
       " '10the',\n",
       " '10thfirstday',\n",
       " '10thmountaindivision',\n",
       " '10thplanetjiujitsu',\n",
       " '10thtimethisweek',\n",
       " '10toes',\n",
       " '10tv',\n",
       " '10u',\n",
       " '10up',\n",
       " '10upsummit',\n",
       " '10v12',\n",
       " '10weekstoday',\n",
       " '10weekstogo',\n",
       " '10willcox',\n",
       " '10x',\n",
       " '10xgrowthcon',\n",
       " '10y',\n",
       " '10year',\n",
       " '10years',\n",
       " '10yearscancerfree',\n",
       " '10yearsfromnow',\n",
       " '10yearsoffmylife',\n",
       " '10yearsofjonasbrothers',\n",
       " '10yearsofmisery',\n",
       " '10yearsoftheo2',\n",
       " '10yearstoheyybabyy',\n",
       " '10yearweddinganniversary',\n",
       " '10yo',\n",
       " '10yr',\n",
       " '10yrars',\n",
       " '10yrboy',\n",
       " '10yrgirl',\n",
       " '10yro',\n",
       " '10yrs',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '11000',\n",
       " '11000hourstrynoteven100',\n",
       " '1100m',\n",
       " '1101',\n",
       " '1104380',\n",
       " '1109',\n",
       " '110a',\n",
       " '110above',\n",
       " '110f',\n",
       " '110km',\n",
       " '111',\n",
       " '1111',\n",
       " '111111',\n",
       " '1112',\n",
       " '1113om',\n",
       " '1115',\n",
       " '1116sam',\n",
       " '111lbs',\n",
       " '111st',\n",
       " '111th',\n",
       " '112',\n",
       " '1122',\n",
       " '1124',\n",
       " '11298',\n",
       " '113',\n",
       " '1130',\n",
       " '1130am',\n",
       " '1130pm',\n",
       " '1131',\n",
       " '1132',\n",
       " '1133',\n",
       " '113events',\n",
       " '113f',\n",
       " '113k',\n",
       " '114',\n",
       " '1140',\n",
       " '11400',\n",
       " '1140wrva',\n",
       " '11427',\n",
       " '1143',\n",
       " '1145',\n",
       " '11478529',\n",
       " '1148mong',\n",
       " '115',\n",
       " '1150',\n",
       " '11500',\n",
       " '1154638',\n",
       " '11572',\n",
       " '115k',\n",
       " '116',\n",
       " '1160',\n",
       " '116123',\n",
       " '1164davidxx',\n",
       " '116th',\n",
       " '117',\n",
       " '1176',\n",
       " '117eur',\n",
       " '117mph',\n",
       " '118',\n",
       " '118bpm',\n",
       " '118years',\n",
       " '119',\n",
       " '1196361966',\n",
       " '1197',\n",
       " '119lbs',\n",
       " '11a',\n",
       " '11a6',\n",
       " '11ak111',\n",
       " '11alivenews',\n",
       " '11am',\n",
       " '11b',\n",
       " '11bjp11',\n",
       " '11c',\n",
       " '11clintjames11',\n",
       " '11days',\n",
       " '11daysoff',\n",
       " '11eleven',\n",
       " '11eleven07',\n",
       " '11gm',\n",
       " '11hours',\n",
       " '11hoursmore',\n",
       " '11hr',\n",
       " '11hrs',\n",
       " '11ish',\n",
       " '11k',\n",
       " '11kg',\n",
       " '11kirsty11',\n",
       " '11l',\n",
       " '11larky',\n",
       " '11lbs',\n",
       " '11m',\n",
       " '11miami',\n",
       " '11mins',\n",
       " '11mph',\n",
       " '11mpltldr',\n",
       " '11nights',\n",
       " '11nightsleftandcounting',\n",
       " '11oct2017',\n",
       " '11on7',\n",
       " '11p',\n",
       " '11pm',\n",
       " '11points',\n",
       " '11pts',\n",
       " '11put',\n",
       " '11s',\n",
       " '11th',\n",
       " '11thadmission',\n",
       " '11thhour',\n",
       " '11thhourman',\n",
       " '11thhourtheatre',\n",
       " '11thweek',\n",
       " '11u',\n",
       " '11v11',\n",
       " '11w',\n",
       " '11weeks',\n",
       " '11williecalhoun',\n",
       " '11wishing',\n",
       " '11y',\n",
       " '11yo',\n",
       " '11yr',\n",
       " '11yrs',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '12000',\n",
       " '1201',\n",
       " '1201bf',\n",
       " '1203',\n",
       " '1204',\n",
       " '1207',\n",
       " '1207757681',\n",
       " '120ct',\n",
       " '120k',\n",
       " '120m',\n",
       " '120mins',\n",
       " '120mm',\n",
       " '120mph',\n",
       " '120yearsttt',\n",
       " '121',\n",
       " '12103',\n",
       " '1210pm',\n",
       " '1212',\n",
       " '12120',\n",
       " '1214',\n",
       " '1215',\n",
       " '1216',\n",
       " '1217',\n",
       " '121words',\n",
       " '122',\n",
       " '1222',\n",
       " '1223',\n",
       " '1224',\n",
       " '12252',\n",
       " '12269',\n",
       " '1227',\n",
       " '1228',\n",
       " '122edchat',\n",
       " '122k',\n",
       " '122m',\n",
       " '122nd',\n",
       " '123',\n",
       " '1230',\n",
       " '1230am',\n",
       " '1230pm',\n",
       " '1233newcastle',\n",
       " '12345123lanlan',\n",
       " '123456789',\n",
       " '12345check',\n",
       " '1237',\n",
       " '1239',\n",
       " '123rd',\n",
       " '123reg',\n",
       " '123systems',\n",
       " '123telugu',\n",
       " '124',\n",
       " '12401',\n",
       " '1246',\n",
       " '12463',\n",
       " '125',\n",
       " '1250',\n",
       " '12500',\n",
       " '12529',\n",
       " '125580',\n",
       " '1256',\n",
       " '12561',\n",
       " '125cr',\n",
       " '125k',\n",
       " '125km',\n",
       " '125mph',\n",
       " '125th',\n",
       " '126',\n",
       " '1263826474x',\n",
       " '12662040',\n",
       " '126milla',\n",
       " '126th',\n",
       " '127',\n",
       " '1270',\n",
       " '12708',\n",
       " '1271',\n",
       " '12744',\n",
       " '12777k',\n",
       " '127842',\n",
       " '127daystogo',\n",
       " '128',\n",
       " '12805',\n",
       " '1280spence',\n",
       " '1280sports',\n",
       " '12815',\n",
       " '12816',\n",
       " '12817',\n",
       " '1285',\n",
       " '12851k',\n",
       " '128gb',\n",
       " '128mb',\n",
       " '129',\n",
       " '12915',\n",
       " '12935',\n",
       " '1294',\n",
       " '1295mm',\n",
       " '1299edn',\n",
       " '12a',\n",
       " '12am',\n",
       " '12an',\n",
       " '12andrewle',\n",
       " '12aug',\n",
       " '12billion',\n",
       " '12days',\n",
       " '12daysofgratitude',\n",
       " '12daystwitter',\n",
       " '12earnmoney',\n",
       " '12east',\n",
       " '12fps',\n",
       " '12g',\n",
       " '12gb',\n",
       " '12hour',\n",
       " '12hours',\n",
       " '12hourshift',\n",
       " '12hr',\n",
       " '12hrs',\n",
       " '12k',\n",
       " '12lb',\n",
       " '12lbs',\n",
       " '12m',\n",
       " '12mi',\n",
       " '12mil',\n",
       " '12mins',\n",
       " '12mls',\n",
       " '12mm',\n",
       " '12mn',\n",
       " '12mo',\n",
       " '12mobjoey',\n",
       " '12month',\n",
       " '12mths',\n",
       " '12n',\n",
       " '12news',\n",
       " '12nn',\n",
       " '12noon',\n",
       " '12oaks',\n",
       " '12oz',\n",
       " '12p',\n",
       " '12pc',\n",
       " '12pk',\n",
       " '12pks',\n",
       " '12pm',\n",
       " '12reasonswhy',\n",
       " '12s',\n",
       " '12seatsofchristmas',\n",
       " '12sfun',\n",
       " '12steps',\n",
       " '12straighthoursofalex',\n",
       " '12tb',\n",
       " '12th',\n",
       " '12thaug',\n",
       " '12thblue',\n",
       " '12thburkey',\n",
       " '12thman',\n",
       " '12thmantish',\n",
       " '12to5',\n",
       " '12tribes',\n",
       " '12u',\n",
       " '12voltman60',\n",
       " '12willpower',\n",
       " '12wks',\n",
       " '12x',\n",
       " '12x12',\n",
       " '12y',\n",
       " '12yearsold',\n",
       " '12yo',\n",
       " '12yr',\n",
       " '12yrs',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '13000',\n",
       " '1300m',\n",
       " '1303',\n",
       " '1307',\n",
       " '130mm',\n",
       " '130s',\n",
       " '131',\n",
       " '1312',\n",
       " '1313',\n",
       " '1318',\n",
       " '131e',\n",
       " '131s',\n",
       " '132',\n",
       " '1320',\n",
       " '1322',\n",
       " '1324',\n",
       " '1327',\n",
       " '133',\n",
       " '1331432760',\n",
       " '1335',\n",
       " '1336',\n",
       " '134',\n",
       " '1340',\n",
       " '1344',\n",
       " '134lbs',\n",
       " '135',\n",
       " '135million',\n",
       " '135th',\n",
       " '136',\n",
       " '136k',\n",
       " '136th',\n",
       " '137',\n",
       " '138',\n",
       " '1380',\n",
       " '139',\n",
       " '1392',\n",
       " '139eur',\n",
       " '13a',\n",
       " '13crownofficial',\n",
       " '13crowns',\n",
       " '13days',\n",
       " '13dayswaiting',\n",
       " '13h',\n",
       " '13h00',\n",
       " '13hr',\n",
       " '13hrs',\n",
       " '13isgodsend',\n",
       " '13jmall',\n",
       " '13k',\n",
       " '13lb',\n",
       " '13min',\n",
       " '13mm',\n",
       " '13months',\n",
       " '13novembre2015',\n",
       " '13pm',\n",
       " ...]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# build analyzers (bag-of-words)\n",
    "count_vect = CountVectorizer(max_features = 1750000, stop_words = {'english'}, tokenizer = get_tokenize(), ngram_range = (1,2)) #\n",
    "count_vect.fit(df_train.text)\n",
    "# 2. Transform documents to document-term matrix.\n",
    "train_BOW_features = count_vect.transform(df_train.text)\n",
    "test_BOW_features = count_vect.transform(df_test.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 1750000)\n",
      "(411972, 1750000)\n"
     ]
    }
   ],
   "source": [
    "print(train_BOW_features.shape)\n",
    "print(test_BOW_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(train_BOW_features, df_train.emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sdgc = SGDClassifier()\n",
    "sdgc.fit(train_BOW_features, df_train.emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10644/2153292035.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_train_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msdgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_BOW_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msdgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_BOW_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    289\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         scores = safe_sparse_dot(X, self.coef_.T,\n\u001b[0m\u001b[0;32m    292\u001b[0m                                  dense_output=True) + self.intercept_\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;31m# csr_matvecs or csc_matvecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvecs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[0m\u001b[0;32m    492\u001b[0m            other.ravel(), result.ravel())\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_train_pred = sdgc.predict(train_BOW_features)\n",
    "y_test_pred = sdgc.predict(test_BOW_features)\n",
    "print(y_train_pred)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MultiNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(train_BOW_features, df_train.emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgust' 'sadness' 'fear' ... 'joy' 'sadness' 'joy']\n",
      "['anticipation' 'anticipation' 'anticipation' ... 'joy' 'joy' 'sadness']\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(train_BOW_features)\n",
    "y_test_pred = clf.predict(test_BOW_features)\n",
    "print(y_train_pred)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lee\\AppData\\Local\\Temp/ipykernel_11304/2956050169.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['emotion'] = y_test_pred\n"
     ]
    }
   ],
   "source": [
    "df_test['emotion'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             194396\n",
       "sadness          71007\n",
       "disgust          68782\n",
       "anticipation     44473\n",
       "trust            27392\n",
       "fear              5325\n",
       "anger              317\n",
       "surprise           280\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joy             167767\n",
    "# disgust          84127\n",
    "# sadness          71631\n",
    "# anticipation     44885\n",
    "# trust            34813\n",
    "# fear              7462\n",
    "# anger              711\n",
    "# surprise           576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy             516017\n",
       "anticipation    248935\n",
       "trust           205478\n",
       "sadness         193437\n",
       "disgust         139101\n",
       "fear             63999\n",
       "surprise         48729\n",
       "anger            39867\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "str = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('submit' + str + '.csv',columns=['id', 'emotion'], index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41b3add1b201b86e90b13a64b00fa9aafc4e6c3aecb26345394dc84f6e342faf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
